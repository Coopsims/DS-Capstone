{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Review Prediction - Model Inference\n",
    "**Author:** Ben\n",
    "\n",
    "**Project:** Capstone - Star Rating Prediction\n",
    "\n",
    "**Objective:** Load trained models and make predictions on new reviews\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook provides inference capabilities for the trained models:\n",
    "- Random Forest (Text-Only)\n",
    "- Random Forest (Text + Metadata)\n",
    "- XGBoost (Text + Metadata)\n",
    "\n",
    "**Usage:** Simply modify the `fake_review` variable with your own review text and run all cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T00:13:39.971252300Z",
     "start_time": "2026-01-29T00:13:38.463942100Z"
    }
   },
   "source": "# Import libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom datetime import datetime\nimport pickle\nimport os\n\n# Sklearn imports\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom scipy import sparse\nfrom scipy.sparse import hstack\n\n# XGBoost import\nfrom xgboost import XGBClassifier\n\n# PyTorch imports for LSTM\nimport torch\nimport torch.nn as nn\n\nwarnings.filterwarnings('ignore')\n\n# Set visualization defaults\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette(\"husl\")\nplt.rcParams['figure.figsize'] = (12, 6)\nplt.rcParams['font.size'] = 10\n\nprint(\"Libraries imported successfully\")\nprint(f\"Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n",
      "Current time: 2026-01-28 17:13:39\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T00:13:40.005416900Z",
     "start_time": "2026-01-29T00:13:39.978490400Z"
    }
   },
   "source": "def extract_metadata_features(df, encoders=None, fit=True):\n    \"\"\"\n    Extract and encode metadata features from the dataframe.\n    \n    Args:\n        df: Input dataframe\n        encoders: Dictionary of fitted encoders (for test set)\n        fit: Whether to fit encoders (True for train, False for test)\n    \n    Returns:\n        features: Numpy array of features\n        encoders: Dictionary of encoders (if fit=True)\n    \"\"\"\n    features_list = []\n    feature_names = []\n    \n    if encoders is None:\n        encoders = {}\n    \n    # 1. Numerical features\n    numerical_features = [\n        'word_count',\n        'char_count', \n        'useful',\n        'funny',\n        'cool',\n        'total_engagement',\n        'review_count',\n        'user_review_count'\n    ]\n    \n    for col in numerical_features:\n        if col in df.columns:\n            values = df[col].fillna(0).values.reshape(-1, 1)\n            \n            if fit:\n                scaler = StandardScaler()\n                scaled_values = scaler.fit_transform(values)\n                encoders[f'{col}_scaler'] = scaler\n            else:\n                scaled_values = encoders[f'{col}_scaler'].transform(values)\n            \n            features_list.append(scaled_values)\n            feature_names.append(col)\n    \n    # 2. Binary features\n    binary_features = ['is_open']\n    for col in binary_features:\n        if col in df.columns:\n            features_list.append(df[col].fillna(1).values.reshape(-1, 1))\n            feature_names.append(col)\n    \n    # 3. Temporal features\n    temporal_features = ['year', 'month', 'day_of_week']\n    for col in temporal_features:\n        if col in df.columns:\n            values = df[col].fillna(df[col].mode()[0] if len(df[col].mode()) > 0 else 0).values.reshape(-1, 1)\n            features_list.append(values)\n            feature_names.append(col)\n    \n    # 4. Categorical features - State (top 10 only)\n    if 'state' in df.columns:\n        if fit:\n            top_states = df['state'].value_counts().head(10).index.tolist()\n            encoders['top_states'] = top_states\n        else:\n            top_states = encoders['top_states']\n        \n        # Create binary features for top states\n        for state in top_states:\n            features_list.append((df['state'] == state).astype(int).values.reshape(-1, 1))\n            feature_names.append(f'state_{state}')\n    \n    # 5. Categories - Extract top categories\n    if 'categories' in df.columns:\n        if fit:\n            # Find most common categories\n            all_cats = []\n            for cats in df['categories'].fillna('').str.split(', '):\n                all_cats.extend(cats)\n            from collections import Counter\n            top_categories = [cat for cat, _ in Counter(all_cats).most_common(20) if cat]\n            encoders['top_categories'] = top_categories\n        else:\n            top_categories = encoders['top_categories']\n        \n        # Create binary features for top categories\n        for category in top_categories:\n            has_category = df['categories'].fillna('').str.contains(category, case=False, regex=False)\n            features_list.append(has_category.astype(int).values.reshape(-1, 1))\n            feature_names.append(f'category_{category.replace(\" \", \"_\")}')\n    \n    # 6. User activity level\n    if 'user_activity' in df.columns:\n        activity_mapping = {\n            '1 review': 1,\n            '2-5 reviews': 2,\n            '6-20 reviews': 3,\n            '21-100 reviews': 4,\n            '100+ reviews': 5\n        }\n        activity_encoded = df['user_activity'].map(activity_mapping).fillna(1).values.reshape(-1, 1)\n        features_list.append(activity_encoded)\n        feature_names.append('user_activity_level')\n    \n    # Combine all features\n    X_metadata = np.hstack(features_list)\n    \n    if fit:\n        return X_metadata, encoders, feature_names\n    else:\n        return X_metadata, feature_names\n\n\n# Define BiLSTM model architecture (must match training)\nclass BiLSTM(nn.Module):\n    \"\"\"\n    Bidirectional LSTM model for text classification.\n    \"\"\"\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, \n                 n_layers=2, dropout=0.5):\n        super(BiLSTM, self).__init__()\n        \n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, \n                           batch_first=True, dropout=dropout if n_layers > 1 else 0,\n                           bidirectional=True)\n        self.dropout = nn.Dropout(dropout)\n        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n        \n    def forward(self, text):\n        embedded = self.dropout(self.embedding(text))\n        output, (hidden, cell) = self.lstm(embedded)\n        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n        hidden = self.dropout(hidden)\n        output = self.fc(hidden)\n        return output\n\n\ndef simple_tokenizer(text):\n    \"\"\"Simple word tokenizer - split on whitespace and lowercase.\"\"\"\n    return text.lower().split()\n\n\ndef text_to_sequence(text, word2idx, max_len=200):\n    \"\"\"\n    Convert text to sequence of word indices.\n    \"\"\"\n    tokens = simple_tokenizer(text)\n    sequence = [word2idx.get(word, word2idx['<UNK>']) for word in tokens]\n    if max_len:\n        sequence = sequence[:max_len]\n    return sequence\n\n\ndef pad_sequences(sequences, max_len, pad_value=0):\n    \"\"\"\n    Pad sequences to the same length.\n    \"\"\"\n    padded = np.zeros((len(sequences), max_len), dtype=np.int64)\n    for i, seq in enumerate(sequences):\n        length = min(len(seq), max_len)\n        padded[i, :length] = seq[:length]\n    return padded\n\n\nprint(\"Helper functions defined\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Pre-Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T00:13:40.457764300Z",
     "start_time": "2026-01-29T00:13:40.008008Z"
    }
   },
   "source": "# Check if models exist\nmodels_exist = (\n    os.path.exists('../Outputs/Models/rf_text.pkl') and\n    os.path.exists('../Outputs/Models/rf_combined.pkl') and\n    os.path.exists('../Outputs/Models/gbm.pkl') and\n    os.path.exists('../Outputs/Models/tfidf_vectorizer.pkl') and\n    os.path.exists('../Outputs/Models/metadata_encoders.pkl') and\n    os.path.exists('../Outputs/Models/lstm_best.pt') and\n    os.path.exists('../Outputs/Models/vocab.pkl')\n)\n\nif not models_exist:\n    raise FileNotFoundError(\n        \"Pre-trained models not found!\\n\"\n        \"Please run the training notebooks first to train the models.\"\n    )\n\nprint(\"=\" * 80)\nprint(\"LOADING PRE-TRAINED MODELS\")\nprint(\"=\" * 80)\n\n# Load statistical models\nwith open('../Outputs/Models/rf_text.pkl', 'rb') as f:\n    rf_text = pickle.load(f)\nprint(\"Loaded: rf_text.pkl\")\n\nwith open('../Outputs/Models/rf_combined.pkl', 'rb') as f:\n    rf_combined = pickle.load(f)\nprint(\"Loaded: rf_combined.pkl\")\n\nwith open('../Outputs/Models/gbm.pkl', 'rb') as f:\n    gbm = pickle.load(f)\nprint(\"Loaded: gbm.pkl\")\n\nwith open('../Outputs/Models/tfidf_vectorizer.pkl', 'rb') as f:\n    tfidf = pickle.load(f)\nprint(\"Loaded: tfidf_vectorizer.pkl\")\n\nwith open('../Outputs/Models/metadata_encoders.pkl', 'rb') as f:\n    metadata_encoders = pickle.load(f)\nprint(\"Loaded: metadata_encoders.pkl\")\n\n# Load LSTM model\nwith open('../Outputs/Models/vocab.pkl', 'rb') as f:\n    vocab_data = pickle.load(f)\n    word2idx = vocab_data['word2idx']\n    idx2word = vocab_data['idx2word']\nprint(\"Loaded: vocab.pkl\")\n\n# LSTM hyperparameters (must match training)\nVOCAB_SIZE = len(word2idx)\nEMBEDDING_DIM = 100\nHIDDEN_DIM = 256\nOUTPUT_DIM = 5\nMAX_LEN = 200\n\n# Initialize LSTM model\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nlstm_model = BiLSTM(\n    vocab_size=VOCAB_SIZE,\n    embedding_dim=EMBEDDING_DIM,\n    hidden_dim=HIDDEN_DIM,\n    output_dim=OUTPUT_DIM,\n    n_layers=2,\n    dropout=0.5\n).to(device)\n\n# Load trained weights\nlstm_model.load_state_dict(torch.load('../Outputs/Models/lstm_best.pt', map_location=device))\nlstm_model.eval()\nprint(\"Loaded: lstm_best.pt\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"All models loaded successfully!\")\nprint(f\"Using device for LSTM: {device}\")\nprint(\"=\" * 80)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING PRE-TRAINED MODELS\n",
      "================================================================================\n",
      "Loaded: rf_text.pkl\n",
      "Loaded: rf_combined.pkl\n",
      "Loaded: gbm.pkl\n",
      "Loaded: tfidf_vectorizer.pkl\n",
      "Loaded: metadata_encoders.pkl\n",
      "Loaded: vocab.pkl\n",
      "Loaded: lstm_best.pt\n",
      "\n",
      "================================================================================\n",
      "All models loaded successfully!\n",
      "Using device for LSTM: cuda\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make Predictions\n",
    "\n",
    "### Configuration\n",
    "Modify the variables below to customize your prediction:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T00:20:13.300452300Z",
     "start_time": "2026-01-29T00:20:13.287654700Z"
    }
   },
   "source": [
    "# ============================================================================\n",
    "# MODIFY THESE VARIABLES TO TEST YOUR OWN REVIEWS\n",
    "# ============================================================================\n",
    "\n",
    "# Review text (required)\n",
    "review_text = \"The food was just fine\"\n",
    "\n",
    "# Optional metadata (adjust as needed)\n",
    "review_metadata = {\n",
    "    'useful': 0,           # Number of useful votes\n",
    "    'funny': 0,            # Number of funny votes\n",
    "    'cool': 0,             # Number of cool votes\n",
    "    'review_count': 5,    # Business review count\n",
    "    'user_review_count': 5,  # User's total review count\n",
    "    'is_open': 1,          # Is business open? (1=Yes, 0=No)\n",
    "    'year': 2024,          # Year of review\n",
    "    'month': 1,            # Month of review (1-12)\n",
    "    'day_of_week': 0,      # Day of week (0=Monday, 6=Sunday)\n",
    "    'state': 'CA',         # State abbreviation (e.g., 'CA', 'PA', 'FL')\n",
    "    'categories': 'Restaurants',  # Business categories\n",
    "    'user_activity': '6-20 reviews'  # User activity level\n",
    "}\n",
    "\n",
    "# ============================================================================"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Prediction"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T00:20:15.013989500Z",
     "start_time": "2026-01-29T00:20:14.538333500Z"
    }
   },
   "source": "print(\"=\" * 80)\nprint(\"MAKING PREDICTIONS\")\nprint(\"=\" * 80)\n\nprint(f\"\\nReview Text: {review_text}\")\nprint(f\"Review Length: {len(review_text)} characters, {len(review_text.split())} words\")\n\n# Step 1: Transform text with TF-IDF\nreview_tfidf = tfidf.transform([review_text])\nprint(f\"\\nText transformed to TF-IDF: {review_tfidf.shape}\")\n\n# Step 2: Create metadata features\nreview_df = pd.DataFrame({\n    'text': [review_text],\n    'word_count': [len(review_text.split())],\n    'char_count': [len(review_text)],\n    'useful': [review_metadata['useful']],\n    'funny': [review_metadata['funny']],\n    'cool': [review_metadata['cool']],\n    'total_engagement': [review_metadata['useful'] + review_metadata['funny'] + review_metadata['cool']],\n    'review_count': [review_metadata['review_count']],\n    'user_review_count': [review_metadata['user_review_count']],\n    'is_open': [review_metadata['is_open']],\n    'year': [review_metadata['year']],\n    'month': [review_metadata['month']],\n    'day_of_week': [review_metadata['day_of_week']],\n    'state': [review_metadata['state']],\n    'categories': [review_metadata['categories']],\n    'user_activity': [review_metadata['user_activity']]\n})\n\nmetadata_array, _ = extract_metadata_features(review_df, encoders=metadata_encoders, fit=False)\nmetadata_sparse = sparse.csr_matrix(metadata_array)\nprint(f\"Metadata features created: {metadata_sparse.shape}\")\n\n# Step 3: Combine text + metadata\nreview_combined = hstack([review_tfidf, metadata_sparse])\nprint(f\"Combined features: {review_combined.shape} (expected: (1, 7043))\")\n\n# Step 4: Prepare text for LSTM\nreview_sequence = text_to_sequence(review_text, word2idx, MAX_LEN)\nreview_padded = pad_sequences([review_sequence], MAX_LEN)\nreview_tensor = torch.LongTensor(review_padded).to(device)\nprint(f\"LSTM sequence prepared: {review_tensor.shape}\")\n\n# Step 5: Make predictions\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PREDICTIONS\")\nprint(\"=\" * 80)\n\n# Get class predictions\npred_rf_text = rf_text.predict(review_tfidf)[0]\npred_rf_combined = rf_combined.predict(review_combined)[0]\npred_xgb = gbm.predict(review_combined)[0] + 1\n\n# LSTM prediction\nwith torch.no_grad():\n    lstm_output = lstm_model(review_tensor)\n    lstm_probs = torch.softmax(lstm_output, dim=1).cpu().numpy()[0]\n    pred_lstm = lstm_output.argmax(1).cpu().numpy()[0] + 1  # Convert 0-4 to 1-5\n\n# Get probability distributions\nprob_rf_text = rf_text.predict_proba(review_tfidf)[0]\nprob_rf_combined = rf_combined.predict_proba(review_combined)[0]\nprob_xgb = gbm.predict_proba(review_combined)[0]\nprob_lstm = lstm_probs\n\nprint(f\"\\nRandom Forest (Text-Only):       {int(pred_rf_text)} stars\")\nprint(f\"Random Forest (Text + Metadata): {int(pred_rf_combined)} stars\")\nprint(f\"XGBoost (Text + Metadata):       {int(pred_xgb)} stars\")\nprint(f\"LSTM (Text-Only):                {int(pred_lstm)} stars\")\n\n# Display probability distributions\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PROBABILITY DISTRIBUTIONS\")\nprint(\"=\" * 80)\n\nprint(\"\\nRandom Forest (Text-Only):\")\nfor i, prob in enumerate(prob_rf_text, 1):\n    bar = '█' * int(prob * 50)\n    print(f\"  {i} star: {prob:6.2%} {bar}\")\n\nprint(\"\\nRandom Forest (Text + Metadata):\")\nfor i, prob in enumerate(prob_rf_combined, 1):\n    bar = '█' * int(prob * 50)\n    print(f\"  {i} star: {prob:6.2%} {bar}\")\n\nprint(\"\\nXGBoost (Text + Metadata):\")\nfor i, prob in enumerate(prob_xgb, 1):\n    bar = '█' * int(prob * 50)\n    print(f\"  {i} star: {prob:6.2%} {bar}\")\n\nprint(\"\\nLSTM (Text-Only):\")\nfor i, prob in enumerate(prob_lstm, 1):\n    bar = '█' * int(prob * 50)\n    print(f\"  {i} star: {prob:6.2%} {bar}\")\n\n# Show consensus\npredictions = [pred_rf_text, pred_rf_combined, pred_xgb, pred_lstm]\nconsensus = np.bincount([int(p) for p in predictions]).argmax()\nunanimous = len(set([int(p) for p in predictions])) == 1\n\nprint(\"\\n\" + \"=\" * 80)\nif unanimous:\n    print(f\"UNANIMOUS PREDICTION: {int(consensus)} STARS\")\nelse:\n    print(f\"CONSENSUS PREDICTION: {int(consensus)} STARS\")\nprint(\"=\" * 80)\n\n# Create visualization\nprint(\"\\n\" + \"=\" * 80)\nprint(\"GENERATING VISUALIZATION\")\nprint(\"=\" * 80)\n\n# Check if file exists and generate unique filename\nbase_filename = '../Outputs/Plots/prediction_probabilities'\nfilename = f'{base_filename}.png'\ncounter = 1\n\nwhile os.path.exists(filename):\n    filename = f'{base_filename}_{counter}.png'\n    counter += 1\n\n# Create figure\nfig, axes = plt.subplots(1, 4, figsize=(20, 5))\n\n# Prepare data\nstar_ratings = np.arange(1, 6)\nmodels_data = [\n    ('Random Forest\\n(Text-Only)', prob_rf_text, pred_rf_text),\n    ('Random Forest\\n(Text + Metadata)', prob_rf_combined, pred_rf_combined),\n    ('XGBoost\\n(Text + Metadata)', prob_xgb, pred_xgb),\n    ('LSTM\\n(Text-Only)', prob_lstm, pred_lstm)\n]\n\n# Plot each model\nfor idx, (model_name, probs, prediction) in enumerate(models_data):\n    ax = axes[idx]\n    \n    # Create bar chart\n    colors = ['#ff6b6b' if i+1 == int(prediction) else '#4ecdc4' for i in range(5)]\n    bars = ax.bar(star_ratings, probs, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n    \n    # Highlight predicted class\n    bars[int(prediction) - 1].set_edgecolor('red')\n    bars[int(prediction) - 1].set_linewidth(3)\n    \n    # Add percentage labels on bars\n    for i, (star, prob) in enumerate(zip(star_ratings, probs)):\n        ax.text(star, prob + 0.02, f'{prob:.1%}', ha='center', va='bottom', fontweight='bold', fontsize=10)\n    \n    # Formatting\n    ax.set_xlabel('Star Rating', fontweight='bold', fontsize=12)\n    ax.set_ylabel('Probability', fontweight='bold', fontsize=12)\n    ax.set_title(f'{model_name}\\nPrediction: {int(prediction)} stars', fontweight='bold', fontsize=12)\n    ax.set_xticks(star_ratings)\n    ax.set_ylim(0, max(probs) + 0.15)\n    ax.grid(axis='y', alpha=0.3, linestyle='--')\n\n# Add review text as suptitle (truncate if too long)\nreview_display = review_text if len(review_text) <= 80 else review_text[:77] + '...'\nfig.suptitle(f'Review: \"{review_display}\"', fontsize=14, fontweight='bold', y=1.02)\n\nplt.tight_layout()\nplt.savefig(filename, dpi=300, bbox_inches='tight')\nplt.close()\n\nprint(f\"\\nVisualization saved: {filename}\")\nprint(\"=\" * 80)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MAKING PREDICTIONS\n",
      "================================================================================\n",
      "\n",
      "Review Text: The food was just fine\n",
      "Review Length: 22 characters, 5 words\n",
      "\n",
      "Text transformed to TF-IDF: (1, 7000)\n",
      "Metadata features created: (1, 43)\n",
      "Combined features: (1, 7043) (expected: (1, 7043))\n",
      "LSTM sequence prepared: torch.Size([1, 200])\n",
      "\n",
      "================================================================================\n",
      "PREDICTIONS\n",
      "================================================================================\n",
      "\n",
      "Random Forest (Text-Only):       2 stars\n",
      "Random Forest (Text + Metadata): 5 stars\n",
      "XGBoost (Text + Metadata):       1 stars\n",
      "LSTM (Text-Only):                3 stars\n",
      "\n",
      "================================================================================\n",
      "PROBABILITY DISTRIBUTIONS\n",
      "================================================================================\n",
      "\n",
      "Random Forest (Text-Only):\n",
      "  1 star: 19.52% █████████\n",
      "  2 star: 20.86% ██████████\n",
      "  3 star: 20.41% ██████████\n",
      "  4 star: 19.07% █████████\n",
      "  5 star: 20.14% ██████████\n",
      "\n",
      "Random Forest (Text + Metadata):\n",
      "  1 star: 21.85% ██████████\n",
      "  2 star: 20.15% ██████████\n",
      "  3 star: 18.15% █████████\n",
      "  4 star: 17.42% ████████\n",
      "  5 star: 22.43% ███████████\n",
      "\n",
      "XGBoost (Text + Metadata):\n",
      "  1 star: 37.42% ██████████████████\n",
      "  2 star: 23.05% ███████████\n",
      "  3 star: 15.86% ███████\n",
      "  4 star:  8.87% ████\n",
      "  5 star: 14.80% ███████\n",
      "\n",
      "LSTM (Text-Only):\n",
      "  1 star:  7.40% ███\n",
      "  2 star: 38.05% ███████████████████\n",
      "  3 star: 49.98% ████████████████████████\n",
      "  4 star:  4.11% ██\n",
      "  5 star:  0.46% \n",
      "\n",
      "================================================================================\n",
      "CONSENSUS PREDICTION: 1 STARS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "GENERATING VISUALIZATION\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=32)]: Using backend ThreadingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visualization saved: ../Outputs/Plots/prediction_probabilities_7.png\n",
      "================================================================================\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Batch Predictions (Optional)\n",
    "\n",
    "Use this cell to make predictions on multiple reviews at once:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T00:13:41.466375500Z",
     "start_time": "2026-01-29T00:13:41.341964600Z"
    }
   },
   "source": "# Define multiple reviews to test\nreviews_to_test = [\n    \"Absolutely terrible! The worst experience ever. Never coming back!\",\n    \"It was okay, nothing special. Average food and service.\",\n    \"Amazing! Best restaurant in town! Highly recommend to everyone!\",\n    \"Pretty good experience overall. Would come back.\",\n    \"Disappointing. Expected much better based on the reviews.\"\n]\n\nprint(\"=\" * 80)\nprint(\"BATCH PREDICTIONS\")\nprint(\"=\" * 80)\n\nresults = []\n\nfor i, review in enumerate(reviews_to_test, 1):\n    # Transform for statistical models\n    review_tfidf = tfidf.transform([review])\n    \n    # Create metadata (using defaults)\n    review_df = pd.DataFrame({\n        'text': [review],\n        'word_count': [len(review.split())],\n        'char_count': [len(review)],\n        'useful': [0],\n        'funny': [0],\n        'cool': [0],\n        'total_engagement': [0],\n        'review_count': [50],\n        'user_review_count': [50],\n        'is_open': [1],\n        'year': [2024],\n        'month': [1],\n        'day_of_week': [0],\n        'state': ['CA'],\n        'categories': ['Restaurants'],\n        'user_activity': ['6-20 reviews']\n    })\n    \n    metadata_array, _ = extract_metadata_features(review_df, encoders=metadata_encoders, fit=False)\n    metadata_sparse = sparse.csr_matrix(metadata_array)\n    review_combined = hstack([review_tfidf, metadata_sparse])\n    \n    # Prepare for LSTM\n    review_sequence = text_to_sequence(review, word2idx, MAX_LEN)\n    review_padded = pad_sequences([review_sequence], MAX_LEN)\n    review_tensor = torch.LongTensor(review_padded).to(device)\n    \n    # Predict with all models\n    pred_xgb = int(gbm.predict(review_combined)[0] + 1)\n    \n    with torch.no_grad():\n        lstm_output = lstm_model(review_tensor)\n        pred_lstm = int(lstm_output.argmax(1).cpu().numpy()[0] + 1)\n    \n    results.append({\n        'Review': review[:60] + '...' if len(review) > 60 else review,\n        'XGBoost': pred_xgb,\n        'LSTM': pred_lstm\n    })\n    \n    print(f\"\\n{i}. {review[:70]}...\")\n    print(f\"   XGBoost: {pred_xgb} stars | LSTM: {pred_lstm} stars\")\n\n# Summary\nresults_df = pd.DataFrame(results)\nprint(\"\\n\" + \"=\" * 80)\nprint(\"BATCH RESULTS SUMMARY\")\nprint(\"=\" * 80)\nprint(results_df.to_string(index=False))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BATCH PREDICTIONS\n",
      "================================================================================\n",
      "\n",
      "1. Absolutely terrible! The worst experience ever. Never coming back!...\n",
      "   XGBoost: 1 stars | LSTM: 1 stars\n",
      "\n",
      "2. It was okay, nothing special. Average food and service....\n",
      "   XGBoost: 3 stars | LSTM: 3 stars\n",
      "\n",
      "3. Amazing! Best restaurant in town! Highly recommend to everyone!...\n",
      "   XGBoost: 5 stars | LSTM: 5 stars\n",
      "\n",
      "4. Pretty good experience overall. Would come back....\n",
      "   XGBoost: 3 stars | LSTM: 4 stars\n",
      "\n",
      "5. Disappointing. Expected much better based on the reviews....\n",
      "   XGBoost: 2 stars | LSTM: 2 stars\n",
      "\n",
      "================================================================================\n",
      "BATCH RESULTS SUMMARY\n",
      "================================================================================\n",
      "                                                         Review  XGBoost  LSTM\n",
      "Absolutely terrible! The worst experience ever. Never coming...        1     1\n",
      "        It was okay, nothing special. Average food and service.        3     3\n",
      "Amazing! Best restaurant in town! Highly recommend to everyo...        5     5\n",
      "               Pretty good experience overall. Would come back.        3     4\n",
      "      Disappointing. Expected much better based on the reviews.        2     2\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
